{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Visualizing Model Training <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-&amp;-Config\" data-toc-modified-id=\"Imports-&amp;-Config-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports &amp; Config</a></span></li><li><span><a href=\"#Visualize-Training\" data-toc-modified-id=\"Visualize-Training-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Visualize Training</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports \\& Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set editor width to something sane\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "# get root repository path\n",
    "a = !pwd\n",
    "repo_root = a[0].rsplit('ProGraML', maxsplit=1,)[0] + 'ProGraML'\n",
    "print(repo_root)\n",
    "#insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, repo_root)\n",
    "repo_root = Path(repo_root)\n",
    "\n",
    "import pandas as pd\n",
    "from itertools import cycle\n",
    "\n",
    "import pickle, json\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set log_dir\n",
    "#sub = 'ault_logs_mirror/example_subfolder'\n",
    "#sub = 'ault_logs_mirror/sub10_ts4x2_bs64'\n",
    "sub = 'ault_logs_mirror/basic_run_full_subset_01-21_weird_testset/'\n",
    "log_dir = repo_root / 'deeplearning/ml4pl/poj104/classifyapp_logs' / sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!ls -a {log_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_all_runs(log_dir, subfolders=False, exclude=['test_only']):\n",
    "    assert subfolders == False, 'not implemented'\n",
    "    logs = {}\n",
    "    hyps = {}\n",
    "    for file in log_dir.glob('*_log.json'):\n",
    "        with open(file, 'r') as f:\n",
    "            run_name = file.name.rsplit('_log.json')[0]\n",
    "            # load hyps\n",
    "            hyp_file = file.parent / (run_name + '_params.json')\n",
    "            try:\n",
    "                with open(hyp_file, 'r') as h:\n",
    "                    hyp = json.load(h)\n",
    "            except FileNotFoundError:\n",
    "                hyp = ''\n",
    "            \n",
    "            hyps[run_name] = hyp\n",
    "            \n",
    "            # skip weird files\n",
    "            if run_name[:2] == '._':\n",
    "                continue\n",
    "\n",
    "            print(run_name)\n",
    "            \n",
    "            log = pd.read_json(f, orient='records')\n",
    "            \n",
    "            # handle 'test_only' epochs later!\n",
    "            if log['epoch'].values[0] == 'test_only':\n",
    "                continue\n",
    "            \n",
    "            # flatten dataframe\n",
    "            valid = pd.DataFrame(log.valid_results.tolist(), columns=['valid_loss', 'valid_acc', 'valid_speed'])\n",
    "            train = pd.DataFrame(log.train_results.tolist(), columns=['train_loss', 'train_acc', 'train_speed'])\n",
    "            if hasattr(log, 'test_results'):\n",
    "                test = pd.DataFrame(log.test_results.tolist(), columns=['test_loss', 'test_acc', 'test_speed'])\n",
    "                df = pd.concat([log.epoch, log.time, train, valid, test], axis=1)\n",
    "            else:\n",
    "                df = pd.concat([log.epoch, log.time, train, valid], axis=1)\n",
    "\n",
    "            logs[run_name] = df\n",
    "    return logs, hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs, hyps = get_all_runs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def make_label(name, split, show_hyps=True):\n",
    "    hyp = hyps[name]\n",
    "    hyp_str = ''\n",
    "    if show_hyps and hyp:\n",
    "        # add later: mean_aggr, pos_emb\n",
    "        hyp_str = 'sub' + str(hyp.get('train_subset', [0, 100])) + \\\n",
    "                  'lr' + str(hyp['lr']) + \\\n",
    "                  'bs' + str(hyp['batch_size']) + \\\n",
    "                  'lt' + str(hyp['layer_timesteps']) + \\\n",
    "                  'gsdrop' + str(hyp['graph_state_dropout']) + \\\n",
    "                  'odrop' + str(hyp['output_dropout']) + \\\n",
    "                  'ewdrop' + str(hyp['edge_weight_dropout'])\n",
    "    return hyp_str + '__' + name + '__' + split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(36, 18))\n",
    "cycle_colors=iter(plt.cm.rainbow(np.linspace(0,1,len(logs))))\n",
    "#cycle_colors = cycle(iter(plt.rcParams['axes.prop_cycle'].by_key()['color']))\n",
    "for name, log in logs.items():\n",
    "    c = next(cycle_colors) #next(color)\n",
    "    plt.plot(log['epoch'], log['valid_acc'], label='_nolegend_', ls='dashed', c=c) # , label=make_label(name, 'valid')\n",
    "    plt.plot(log['epoch'], log['train_acc'], label='_nolegend_', ls='dotted', c=c) # make_label(name, 'train')\n",
    "    if hasattr(log, 'test_acc'):\n",
    "        plt.plot(log['epoch'], log['test_acc'], label=make_label(name, 'test') , c=c)\n",
    "#plt.minorticks_on()\n",
    "plt.yticks(np.arange(0, 1, step=0.025))\n",
    "plt.ylim((0.6, 1.0))\n",
    "plt.grid(which='both', linestyle='-')\n",
    "plt.legend(loc='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
