{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset generation: ProGraML x Branch Prediction <a class='tocSkip'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Configs\" data-toc-modified-id=\"Configs-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Configs</a></span></li><li><span><a href=\"#setup-and-download\" data-toc-modified-id=\"setup-and-download-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>setup and download</a></span></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#nx2data\" data-toc-modified-id=\"nx2data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>nx2data</a></span></li><li><span><a href=\"#define-preprocessing-funcs\" data-toc-modified-id=\"define-preprocessing-funcs-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>define preprocessing funcs</a></span></li><li><span><a href=\"#Execute-preprocessing-of-.ll\" data-toc-modified-id=\"Execute-preprocessing-of-.ll-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Execute preprocessing of .ll</a></span></li></ul></li><li><span><a href=\"#investigate\" data-toc-modified-id=\"investigate-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>investigate</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set editor width to something sane\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zacharias/ProGraML\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "# get root repository path\n",
    "a = !pwd\n",
    "REPO_ROOT = a[0].rsplit('ProGraML', maxsplit=1,)[0] + 'ProGraML'\n",
    "print(REPO_ROOT)\n",
    "#insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, REPO_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "import tqdm\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader, InMemoryDataset\n",
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup and download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_name = 'branch_prediction'\n",
    "\n",
    "# Set where to store the dataset and download automagically\n",
    "ds_basepath = Path('/home/zacharias/llvm_datasets/')\n",
    "\n",
    "logs_basepath = ds_basepath / 'logs' / f'{dataset_name}_logs'\n",
    "\n",
    "ds_basepath.mkdir(parents=True, exist_ok=True)\n",
    "ds_path = ds_basepath / f'{dataset_name}_data'\n",
    "ds_path.mkdir(parents=True, exist_ok=True)\n",
    "logs_basepath.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zacharias/llvm_datasets/branch_prediction_data\n",
      "/home/zacharias/ProGraML/deeplearning/ml4pl/poj104/\n",
      "/home/zacharias/llvm_datasets/logs/branch_prediction_logs\n",
      "/home/zacharias/ProGraML/deeplearning/ml4pl/poj104/\n"
     ]
    }
   ],
   "source": [
    "# link those places into poj104 folder\n",
    "\n",
    "data_source = str((ds_basepath / f'{dataset_name}_data').absolute())\n",
    "\n",
    "print(data_source)\n",
    "data_target = REPO_ROOT + '/deeplearning/ml4pl/poj104/'\n",
    "print(data_target)\n",
    "\n",
    "logs_source = str(logs_basepath.absolute())\n",
    "print(logs_source)\n",
    "logs_target = REPO_ROOT + '/deeplearning/ml4pl/poj104/'\n",
    "print(logs_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrwxrwxrwx  1 zacharias zacharias   63 Feb 13 15:41 new_unsupervised_ncc_data -> /mnt/data/llvm/master_thesis_datasets/new_unsupervised_ncc_data\r\n",
      "lrwxrwxrwx  1 zacharias zacharias   68 Feb 13 15:41 new_unsupervised_ncc_logs -> /mnt/data/llvm/master_thesis_datasets/logs/new_unsupervised_ncc_logs\r\n"
     ]
    }
   ],
   "source": [
    "! ln -s {data_source} {data_target}\n",
    "! ln -s {logs_source} {logs_target}\n",
    "! ls -lah {str(REPO_ROOT + '/deeplearning/ml4pl/poj104')} | grep {dataset_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nx2data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def nx2data(nx_graph, class_label=None):\n",
    "    r\"\"\"Converts a :obj:`networkx.Graph` or :obj:`networkx.DiGraph` to a\n",
    "    :class:`torch_geometric.data.Data` instance.\n",
    "\n",
    "    Args:\n",
    "        G (networkx.Graph or networkx.DiGraph): A networkx graph.\n",
    "    \"\"\"\n",
    "\n",
    "    # make sure the nx_graph is encoded properly (since node.x used to be buggy!)\n",
    "    # encoder = GraphNodeEncoder()\n",
    "    # encoder.EncodeNodes(nx_graph)\n",
    "\n",
    "    # collect edge_index\n",
    "    edge_index = torch.tensor(list(nx_graph.edges())).t().contiguous()\n",
    "\n",
    "    # collect edge_attr\n",
    "    positions = []\n",
    "    flows = []\n",
    "\n",
    "    for i, (_, _, edge_data) in enumerate(nx_graph.edges(data=True)):\n",
    "        positions.append(edge_data['position'])\n",
    "        flows.append(edge_data['flow'])\n",
    "\n",
    "    positions = torch.tensor(positions)\n",
    "    flows = torch.tensor(flows)\n",
    "\n",
    "    edge_attr = torch.cat([flows, positions]).view(2, -1).t().contiguous()\n",
    "    \n",
    "    # collect x\n",
    "    types = []\n",
    "    xs = []\n",
    "    \n",
    "    for i, node_data in nx_graph.nodes(data=True):\n",
    "        types.append(node_data['type'])\n",
    "        xs.append(node_data['x'][0])\n",
    "\n",
    "    xs = torch.tensor(xs)\n",
    "    types = torch.tensor(types)\n",
    "    \n",
    "    x = torch.cat([xs, types]).view(2, -1).t().contiguous()\n",
    "\n",
    "    \n",
    "    assert edge_attr.size()[0] == edge_index.size()[1], f'edge_attr={edge_attr.size()} size mismatch with edge_index={edge_index.size()}'\n",
    "    \n",
    "    if class_label is not None:\n",
    "        y = torch.tensor(int(class_label)).view(1)  # <1>\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "    else:\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "    \n",
    "    print(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define preprocessing funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "import traceback\n",
    "import logging\n",
    "\n",
    "def dump(outfile, data, mkdir=True):\n",
    "    if mkdir:\n",
    "        outfile.parent.mkdir(exist_ok=True, parents=True)\n",
    "    with open(outfile, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def _process_single_folder(args, rename_on_fail=False):\n",
    "    \"\"\"The new version will skip tuple creation completely.\"\"\"\n",
    "    folder, dump_nx, dump_data, out_base = args\n",
    "    \n",
    "    problems = \"\"\n",
    "    num_problems = 0\n",
    "    num_processed = 0\n",
    "    \n",
    "    files = list(folder.glob('*.ll'))\n",
    "    \n",
    "    print(f\"=== Opening Folder {str(folder)} with {len(files)} ===\")\n",
    "    \n",
    "    \n",
    "    # iterate over all .ll files in folder and confirm and respectively create the .nx.p and .data.p files\n",
    "    for i, file in enumerate(files):\n",
    "        outfile_nx = out_base / '_nx' / folder.name / (file.name.rsplit('.', 1)[0] + '.nx.p')\n",
    "        outfile_data = out_base / folder.name / (file.name.rsplit('.', 1)[0] + '.data.p')\n",
    "\n",
    "        # find out where to start processing\n",
    "\n",
    "        # skip entirely?\n",
    "        if outfile_data.is_file():\n",
    "            continue\n",
    "\n",
    "        # start at step 2: nx --> data ?\n",
    "        if outfile_nx.is_file():\n",
    "            nx_graph = load(outfile_nx)            \n",
    "            data = nx2data(nx_graph, class_label=None)\n",
    "            dump(outfile_data, data)\n",
    "            continue\n",
    "        \n",
    "        # start in the beginning:\n",
    "        # ~~~ step 1: .ll --> nx ~~~\n",
    "        #if i % 100 == 0:\n",
    "        if i % 1 == 0:\n",
    "            print(f\"{folder.name} - [{i}/{len(files)}] Processing {str(file)} ...\")\n",
    "        \n",
    "        with open(file, 'r') as f:\n",
    "            bytecode = f.read()\n",
    "\n",
    "        try:\n",
    "            nx_graph = builder.Build(bytecode) # nx\n",
    "            if dump_nx:\n",
    "                dump(outfile_nx, nx_graph)\n",
    "            num_processed += 1\n",
    "        except Exception as e:\n",
    "            num_problems += 1\n",
    "            num_processed += 1\n",
    "            \n",
    "            if rename_on_fail:\n",
    "                print(f\"***** FAILING ON {str(file)} ... renaming file to .ll_ \")\n",
    "                problems += str(file)\n",
    "                problems += '\\n'\n",
    "                file.rename(file.with_suffix('.ll_'))\n",
    "            else:\n",
    "                print(f\"***** FAILING ON {str(file)} ...\")\n",
    "                problems += str(file)\n",
    "                problems += '\\n'\n",
    "            logging.error(traceback.format_exc())\n",
    "            continue\n",
    "\n",
    "        # step 2: nx --> data\n",
    "        data = nx2data(nx_graph, class_label=None)\n",
    "        dump(outfile_data, data)\n",
    "    summary = f\"### problems in {num_problems}/{num_processed} files in {str(folder)} ###\\n\"\n",
    "    problems += summary\n",
    "    print(summary)\n",
    "    return problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def preprocess_raw_dir(ds_base, dump_nx=True, dump_data=True, pool_size=12):\n",
    "    \"\"\"Preprocess all .ll files in subfolders of ds_base recursively,\n",
    "    saving .data and .nx pickles to file in {ds_base}_programl/ and in {ds_base}_programl/_nx/\n",
    "    in a directory structure that mirrors that of ds_base.\n",
    "    \"\"\"\n",
    "    assert ds_base.exists(), \"Folder \" + ds_base + \" does not exist.\"\n",
    "\n",
    "    # adapt path type\n",
    "    if type(ds_base) == str:\n",
    "        ds_base = Path(ds_base)\n",
    "        \n",
    "    # create folder for outputs\n",
    "    out_base = ds_base.parent / (ds_base.name + '_programl')\n",
    "    out_base.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # open file to record failed preprocessing attempts\n",
    "    problems = open(out_base / 'problems.txt', 'a')\n",
    "    print(f\"=== DATASET {ds_base}: preprocessing will be saved in {out_base}\")\n",
    "\n",
    "    # get all subfolders that (directly) contain .ll files in ds_base by DFS    \n",
    "    folders_raw = list()\n",
    "    listing_to_explore = [p for p in ds_base.iterdir() if p.is_dir()]\n",
    "    while len(listing_to_explore) > 0:\n",
    "        f = listing_to_explore.pop()\n",
    "        listing_to_explore.extend([p for p in f.iterdir() if p.is_dir()])\n",
    "        f_contents = f.iterdir()\n",
    "        for file in f_contents:\n",
    "            # keep folder if it contains raw .ll files\n",
    "            if file.suffix == '.ll':\n",
    "                folders_raw.append(f)\n",
    "                break\n",
    "    print(f\"preprocessing {len(folders_raw)} subfolders...\")\n",
    "\n",
    "    \n",
    "    # multiprocessed loop over folders\n",
    "    if pool_size != 1:\n",
    "        pool = Pool(processes=pool_size)\n",
    "        task_args = [(folder, dump_nx, dump_data, out_base) for folder in folders_raw]\n",
    "    \n",
    "        for probs in tqdm.tqdm(pool.imap_unordered(_process_single_folder, task_args), total=len(task_args)):\n",
    "            if len(probs) > 15: # don't print empty strings like '\\n\\n\\n'\n",
    "                print(probs, file=problems)\n",
    "    else:\n",
    "        task_args = [(folder, dump_nx, dump_data, out_base) for folder in folders_raw]\n",
    "    \n",
    "        for args in tqdm.tqdm(task_args):\n",
    "            probs = _process_single_folder(args)\n",
    "            if len(probs) > 15: # don't print empty strings like '\\n\\n\\n'\n",
    "                print(probs, file=problems)\n",
    "          \n",
    "          \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    problems.close()\n",
    "    print(f\" * COMPLETED * === DATASET {ds_base}: preprocessing saved to {out_base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute preprocessing of .ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /mnt/data/llvm/master_thesis_datasets/new_unsupervised_ncc_data\n"
     ]
    }
   ],
   "source": [
    "# process .ll data from 'amd_app_sdk'\n",
    "\n",
    "process_dir = ds_path #/ 'amd_app_sdk'\n",
    "print(f\"Processing {process_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preprocess_raw_dir(process_dir, pool_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments:\n",
    "### problems in 0/63 files in /mnt/data/llvm/master_thesis_datasets/unsupervised_ncc_data/amd_app_sdk/amd_ocl ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = Path('/mnt/data/llvm/master_thesis_datasets/unsupervised_ncc_data/eigen/eigen_matmul_3/eigen_matmul-266.ll_')\n",
    "file.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file, 'r') as f:\n",
    "    ll = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "builder.Build(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single file\n",
    "\n",
    "g = load('/home/zacharias/llvm_datasets/test_br_pr/bin/bt.A.ll.pickle')\n",
    "#g = load('/home/zacharias/phd/deeplearning/ml4pl/poj104/test.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1 3\n",
      "2 1 3\n",
      "19 8 27\n",
      "2 201 203\n",
      "2494 36290 38784\n",
      "201 2 203\n",
      "2 1 3\n",
      "2 1 3\n",
      "129 3 132\n",
      "8193 129 8322\n",
      "524289 8193 532482\n",
      "3 129 132\n",
      "129 8193 8322\n",
      "8193 524289 532482\n",
      "8193 129 8322\n",
      "524289 8193 532482\n",
      "524289 8193 532482\n",
      "8193 129 8322\n",
      "129 3 132\n",
      "2147483648 0 2147483648\n",
      "8193 129 8322\n",
      "8193 129 8322\n",
      "129 3 132\n",
      "2147483648 0 2147483648\n",
      "8193 129 8322\n",
      "8193 129 8322\n",
      "129 3 132\n",
      "2147483648 0 2147483648\n",
      "8193 129 8322\n",
      "8193 129 8322\n",
      "129 3 132\n",
      "2147483648 0 2147483648\n",
      "8193 129 8322\n",
      "8193 129 8322\n",
      "129 3 132\n",
      "129 3 132\n",
      "8193 129 8322\n",
      "8193 129 8322\n",
      "129 3 132\n",
      "2147483648 0 2147483648\n",
      "8193 129 8322\n",
      "8193 129 8322\n",
      "129 3 132\n",
      "2317933 11589661 13907594\n",
      "65 2 67\n",
      "4097 65 4162\n",
      "262145 4097 266242\n",
      "2 65 67\n",
      "65 4097 4162\n",
      "4194304 2143289344 2147483648\n",
      "63 3845 3908\n",
      "246017 3845 249862\n",
      "246017 3845 249862\n",
      "1064949 2146418699 2147483648\n",
      "3845 238329 242174\n",
      "3845 222953 226798\n",
      "3845 222953 226798\n",
      "3845 63 3908\n",
      "63 2 65\n",
      "0 2147483648 2147483648\n",
      "63 3845 3908\n",
      "246017 3845 249862\n",
      "246017 3845 249862\n",
      "1064949 2146418699 2147483648\n",
      "3845 238329 242174\n",
      "3845 222953 226798\n",
      "3845 222953 226798\n",
      "3845 63 3908\n",
      "63 2 65\n",
      "2 63 65\n",
      "63 3845 3908\n",
      "246017 3845 249862\n",
      "246017 3845 249862\n",
      "1064949 2146418699 2147483648\n",
      "3845 238329 242174\n",
      "3845 222953 226798\n",
      "3845 222953 226798\n",
      "3845 63 3908\n",
      "63 2 65\n",
      "2 63 65\n",
      "30040987 916375005 946415992\n",
      "238329 3845 242174\n",
      "63 3845 3908\n",
      "63 2 65\n",
      "203 1 204\n",
      "12929 203 13132\n",
      "84222841 2674134226 2758357067\n",
      "827393 52953089 53780482\n",
      "12929 827393 840322\n",
      "203 12929 13132\n",
      "827393 12929 840322\n",
      "52953089 827393 53780482\n",
      "203 12929 13132\n",
      "12929 827393 840322\n",
      "827393 52953089 53780482\n",
      "203 1 204\n",
      "203 12525 12728\n",
      "12525 776489 789014\n",
      "776489 48142257 48918746\n",
      "48142257 776489 48918746\n",
      "12525 776489 789014\n",
      "12525 776489 789014\n",
      "776489 45036305 45812794\n",
      "776489 45036305 45812794\n",
      "12525 776489 789014\n",
      "12525 776489 789014\n",
      "12525 203 12728\n",
      "203 1 204\n",
      "0 2147483648 2147483648\n",
      "203 12525 12728\n",
      "12525 776489 789014\n",
      "776489 48142257 48918746\n",
      "48142257 776489 48918746\n",
      "776489 12525 789014\n",
      "12525 776489 789014\n",
      "776489 12525 789014\n",
      "12525 776489 789014\n",
      "12525 726393 738918\n",
      "726393 45036305 45762698\n",
      "726393 45036305 45762698\n",
      "12525 726393 738918\n",
      "584963 2146898685 2147483648\n",
      "12525 776489 789014\n",
      "12525 776489 789014\n",
      "12525 203 12728\n",
      "203 1 204\n",
      "0 2147483648 2147483648\n",
      "203 12525 12728\n",
      "12525 776489 789014\n",
      "776489 48142257 48918746\n",
      "48142257 776489 48918746\n",
      "12525 776489 789014\n",
      "12525 203 12728\n",
      "203 12525 12728\n",
      "12525 776489 789014\n",
      "12525 776489 789014\n",
      "12525 203 12728\n",
      "12525 776489 789014\n",
      "203 12525 12728\n",
      "203 11717 11920\n",
      "11717 726393 738110\n",
      "726393 45036305 45762698\n",
      "726393 45036305 45762698\n",
      "11717 726393 738110\n",
      "203 11717 11920\n",
      "203 12525 12728\n",
      "12525 776489 789014\n",
      "776489 12525 789014\n",
      "203 12525 12728\n",
      "12525 776489 789014\n",
      "203 12525 12728\n",
      "203 1 204\n",
      "203 12525 12728\n",
      "74196927 2281612121 2355809048\n",
      "48142257 776489 48918746\n",
      "12525 776489 789014\n",
      "12525 203 12728\n",
      "203 1 204\n",
      "202 1 203\n",
      "202 12463 12665\n",
      "12463 772645 785108\n",
      "49449217 772645 50221862\n",
      "772645 49449217 50221862\n",
      "772645 47903929 48676574\n",
      "772645 47903929 48676574\n",
      "772645 47903929 48676574\n",
      "48676573 772645 49449218\n",
      "48676573 772645 49449218\n",
      "772645 12463 785108\n",
      "12463 202 12665\n",
      "202 1 203\n",
      "202 1 203\n",
      "202 12463 12665\n",
      "12463 772645 785108\n",
      "49449217 772645 50221862\n",
      "772645 49449217 50221862\n",
      "772645 47903929 48676574\n",
      "772645 47903929 48676574\n",
      "772645 47903929 48676574\n",
      "48676573 772645 49449218\n",
      "48676573 772645 49449218\n",
      "772645 12463 785108\n",
      "12463 202 12665\n",
      "202 1 203\n",
      "202 1 203\n",
      "202 12463 12665\n",
      "12463 772645 785108\n",
      "49449217 772645 50221862\n",
      "772645 49449217 50221862\n",
      "772645 47903929 48676574\n",
      "772645 47903929 48676574\n",
      "772645 47903929 48676574\n",
      "48676573 772645 49449218\n",
      "48676573 772645 49449218\n",
      "772645 12463 785108\n",
      "12463 202 12665\n",
      "202 1 203\n",
      "202 1 203\n",
      "202 12463 12665\n",
      "12463 772645 785108\n",
      "772645 47903929 48676574\n",
      "772645 47903929 48676574\n",
      "12463 772645 785108\n",
      "12463 202 12665\n",
      "202 1 203\n",
      "65 2 67\n",
      "4097 65 4162\n",
      "262145 4097 266242\n",
      "262145 4097 266242\n",
      "4097 65 4162\n",
      "65 2 67\n",
      "2 63 65\n",
      "63 3845 3908\n",
      "3845 238329 242174\n",
      "3845 238329 242174\n",
      "63 3845 3908\n",
      "63 2 65\n",
      "1 23 24\n",
      "1 23 24\n",
      "16 65 81\n",
      "1 2 3\n",
      "2 1 3\n",
      "1 2 3\n",
      "1 6 7\n",
      "1 6 7\n",
      "1 6 7\n",
      "1 6 7\n",
      "1 6 7\n",
      "1 6 7\n",
      "1 2 3\n",
      "1 6 7\n",
      "1 6 7\n",
      "1 6 7\n",
      "1 6 7\n",
      "1 6 7\n",
      "1 6 7\n",
      "1 6 7\n",
      "1 2 3\n",
      "1 6 7\n",
      "1 6 7\n",
      "1 6 7\n",
      "1 6 7\n",
      "1 6 7\n",
      "1 6 7\n",
      "1 6 7\n",
      "1 2 3\n",
      "1 5 6\n",
      "1 2 3\n",
      "2 2 4\n",
      "\n",
      "\n",
      "\n",
      "{'type': True, 'text': True, 'preprocessed_text': True, 'function': True, 'llvm_profile_true_weight': True, 'llvm_profile_false_weight': True, 'llvm_profile_total_weight': True}\n"
     ]
    }
   ],
   "source": [
    "keys = {}\n",
    "for i,(n, d) in enumerate(g.nodes(data=True)):\n",
    "        #if d['type'] == 0:\n",
    "        for key in d.keys():\n",
    "            if key not in keys:\n",
    "                keys[key] = True\n",
    "                #print(list(d.keys()))\n",
    "        #if 'llvm_profile_true_weight' in list(d.keys()):\n",
    "        if len(list(d.keys())) > 5:\n",
    "            #print(d)\n",
    "            print(d['llvm_profile_true_weight'], d['llvm_profile_false_weight'], d['llvm_profile_total_weight'])\n",
    "        #if i > 50: break\n",
    "\n",
    "print('\\n\\n')\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': [],\n",
       " 'y': [],\n",
       " 'llvm_profile_num_functions': 10,\n",
       " 'llvm_profile_max_function_count': 65556,\n",
       " 'llvm_profile_num_counts': 48,\n",
       " 'llvm_profile_total_count': 1121842441,\n",
       " 'llvm_profile_max_count': 536870912,\n",
       " 'llvm_profile_max_internal_count': 536870912}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['type', 'text', 'preprocessed_text', 'function', 'x', 'y']\n",
      "['type', 'text', 'preprocessed_text', 'function', 'x', 'y']\n",
      "['type', 'text', 'preprocessed_text', 'function', 'x', 'y']\n",
      "['type', 'text', 'preprocessed_text', 'function', 'x', 'y']\n",
      "['type', 'text', 'preprocessed_text', 'function', 'x', 'y']\n",
      "['type', 'text', 'preprocessed_text', 'function', 'x', 'y']\n",
      "\n",
      "\n",
      "\n",
      "{'type': True, 'text': True, 'preprocessed_text': True, 'function': True, 'x': True, 'y': True}\n"
     ]
    }
   ],
   "source": [
    "# whole folder at once\n",
    "\n",
    "keys = {}\n",
    "\n",
    "for file in Path('/home/zacharias/llvm_datasets/branch_prediction_data/').rglob('*ll.pickle'):\n",
    "    g = load(file)\n",
    "    for i,(n, d) in enumerate(g.nodes(data=True)):\n",
    "        #if d['type'] == 0:\n",
    "        for key in d.keys():\n",
    "            if key not in keys:\n",
    "                keys[key] = True\n",
    "                print(list(d.keys()))\n",
    "        #print(d)\n",
    "        #if i > 50: break\n",
    "\n",
    "print('\\n\\n')\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx2data(nx_graph, class_label=None):\n",
    "    r\"\"\"Converts a :obj:`networkx.Graph` or :obj:`networkx.DiGraph` to a\n",
    "    :class:`torch_geometric.data.Data` instance.\n",
    "\n",
    "    Args:\n",
    "        G (networkx.Graph or networkx.DiGraph): A networkx graph.\n",
    "    \"\"\"\n",
    "\n",
    "    # make sure the nx_graph is encoded properly (since node.x used to be buggy!)\n",
    "    # encoder = GraphNodeEncoder()\n",
    "    # encoder.EncodeNodes(nx_graph)\n",
    "\n",
    "    # collect edge_index\n",
    "    edge_index = torch.tensor(list(nx_graph.edges())).t().contiguous()\n",
    "\n",
    "    # collect edge_attr\n",
    "    positions = []\n",
    "    flows = []\n",
    "\n",
    "    for i, (_, _, edge_data) in enumerate(nx_graph.edges(data=True)):\n",
    "        positions.append(edge_data['position'])\n",
    "        flows.append(edge_data['flow'])\n",
    "\n",
    "    positions = torch.tensor(positions)\n",
    "    flows = torch.tensor(flows)\n",
    "\n",
    "    edge_attr = torch.cat([flows, positions]).view(2, -1).t().contiguous()\n",
    "    \n",
    "    # collect x\n",
    "    types = []\n",
    "    xs = []\n",
    "    \n",
    "    for i, node_data in nx_graph.nodes(data=True):\n",
    "        types.append(node_data['type'])\n",
    "        xs.append(node_data['x'][0])\n",
    "\n",
    "    xs = torch.tensor(xs)\n",
    "    types = torch.tensor(types)\n",
    "    \n",
    "    x = torch.cat([xs, types]).view(2, -1).t().contiguous()\n",
    "\n",
    "    \n",
    "    assert edge_attr.size()[0] == edge_index.size()[1], f'edge_attr={edge_attr.size()} size mismatch with edge_index={edge_index.size()}'\n",
    "    \n",
    "    if class_label is not None:\n",
    "        y = torch.tensor(int(class_label)).view(1)  # <1>\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "    else:\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "    \n",
    "    print(data)\n",
    "    return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "762.997px",
    "width": "260px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": "20",
    "lenType": "20",
    "lenVar": "120"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "381.391px",
    "left": "1494.23px",
    "right": "20px",
    "top": "30.9915px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
