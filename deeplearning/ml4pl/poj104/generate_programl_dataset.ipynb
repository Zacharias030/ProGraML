{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Zacharias/Uni/ETH/FS2019/THESIS/code/ProGraML/deeplearning/ml4pl/poj104\r\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "#insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '/Users/Zacharias/Uni/ETH/FS2019/THESIS/code/ProGraML')\n",
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader, InMemoryDataset\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf import text_format\n",
    "from deeplearning.ml4pl.graphs import programl\n",
    "from deeplearning.ml4pl.graphs.labelled import graph_tuple\n",
    "from labm8.py import app\n",
    "\n",
    "#FLAGS = app.FLAGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplearning.ml4pl.graphs.unlabelled.llvm2graph import graph_builder\n",
    "\n",
    "builder = graph_builder.ProGraMLGraphBuilder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Tuple Legend\n",
    "\n",
    "\n",
    "#### ```adjacencies: np.array```\n",
    "\n",
    "A list of adjacency lists, one for each flow type, where an entry in an\n",
    "adjacency list is a <src,dst> tuple of node indices.\n",
    "\n",
    "`Shape (edge_flow_count, edge_count, 2), dtype int32`\n",
    "\n",
    "\n",
    "#### ```edge_positions: np.array```\n",
    "\n",
    "A list of edge positions, one for each edge type. An edge position is an\n",
    "integer in the range 0 <= x < edge_position_max.\n",
    "\n",
    "`Shape (edge_flow_count, edge_count), dtype int32`\n",
    "\n",
    "\n",
    "\n",
    "#### ```node_x: np.array```\n",
    "\n",
    "A list of node feature arrays. Each row is a node, and each column is an\n",
    "feature for that node.\n",
    "\n",
    "`Shape (node_count, node_x_dimensionality), dtype int32`\n",
    "\n",
    "\n",
    "#### ```node_y: Optional[np.array] = None```\n",
    "\n",
    "(optional) A list of node labels arrays.\n",
    "\n",
    "`Shape (node_count, node_y_dimensionality), dtype float32`\n",
    "\n",
    "\n",
    "#### ```graph_x: Optional[np.array] = None```\n",
    "\n",
    "(optional) A list of graph features arrays.\n",
    "\n",
    "`Shape (graph_x_dimensionality) OR (graph_count, graph_x_dimensionality) if\n",
    "graph_count > 1, dtype int32`\n",
    "\n",
    "\n",
    "\n",
    "#### ```graph_y: Optional[np.array] = None```\n",
    "\n",
    "(optional) A vector of graph labels arrays.\n",
    "\n",
    "`Shape (graph_y_dimensionality) OR (graph_count, graph_y_dimensionality) if\n",
    "graph_count > 1, dtype float32`\n",
    "\n",
    "\n",
    "## Disjoint graph properties\n",
    "\n",
    "#### ```disjoint_graph_count: int = 1```\n",
    "\n",
    "The number of disconnected graphs in the tuple.\n",
    "\n",
    "\n",
    "#### ```disjoint_nodes_list: np.array = None```\n",
    "\n",
    "A list of integers which segment the nodes by graph. E.g. with a GraphTuple\n",
    "of two distinct graphs, both with three nodes, nodes_list will be\n",
    "[0, 0, 0, 1, 1, 1].\n",
    "`Shape (node_count), dtype int32:`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proto example\n",
    "from google.protobuf import text_format\n",
    "from deeplearning.ml4pl.graphs import programl_pb2 as proto\n",
    "\n",
    "program_graph = proto.ProgramGraph()\n",
    "\n",
    "with open('40.txt_9G8XzpcFlK.programl_proto', 'r') as f:\n",
    "    proto = f.read()\n",
    "\n",
    "proto = text_format.Parse(proto, program_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from .ll example\n",
    "with open('71.ll', 'r') as f:\n",
    "    ll = f.read()\n",
    "\n",
    "nx_graph = builder.Build(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CreateFromNetworkX', 'CreateFromProgramGraph', 'FromFile', 'FromGraphTuples', 'SetFeaturesAndLabels', 'ToFile', 'ToGraphTuples', 'ToNetworkx', '_asdict', '_field_defaults', '_field_types', '_fields', '_fields_defaults', '_make', '_replace', 'adjacencies', 'call_edge_count', 'control_edge_count', 'count', 'data_edge_count', 'disjoint_graph_count', 'disjoint_nodes_list', 'edge_count', 'edge_position_max', 'edge_positions', 'graph_x', 'graph_x_dimensionality', 'graph_y', 'graph_y_dimensionality', 'has_graph_x', 'has_graph_y', 'has_node_y', 'index', 'is_disjoint_graph', 'node_count', 'node_x', 'node_x_dimensionality', 'node_y', 'node_y_dimensionality']\n",
      "\n",
      "\n",
      "edge_positions [(140,), (269,), (9,)]\n"
     ]
    }
   ],
   "source": [
    "# tuple example\n",
    "graph_tup = graph_tuple.GraphTuple.CreateFromNetworkX(nx_graph)\n",
    "print([a for a in dir(graph_tup) if '__' not in a])\n",
    "print('\\n')\n",
    "print('edge_positions', [x.shape for x in graph_tup.edge_positions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_attr (418,)\n",
      "torch.Size([418, 1])\n",
      "edge_indices [torch.Size([140, 2]), torch.Size([269, 2]), torch.Size([9, 2])]\n",
      "edge_types [(140,), (269,), (9,)]\n",
      "graph_tup.edge_positions [(140,), (269,), (9,)]\n",
      "edge_attr torch.Size([418, 2])\n",
      "x torch.Size([250, 1])\n",
      "y torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# data example\n",
    "edge_indices = [torch.from_numpy(a).to(dtype=torch.long) for a in graph_tup.adjacencies] # list of <M_i, 2>\n",
    "edge_types = [i * np.ones_like(edge_indices[i])[:,0] for i in range(len(edge_indices))]\n",
    "edge_attr = np.hstack(edge_types)\n",
    "print('edge_attr', edge_attr.shape)\n",
    "\n",
    "t_attr = torch.from_numpy(edge_attr).to(dtype=torch.long).view(-1,1)\n",
    "print(t_attr.size())\n",
    "print('edge_indices', [x.shape for x in edge_indices])\n",
    "print('edge_types', [x.shape for x in edge_types])\n",
    "\n",
    "#edge_pos = [torch.from_numpy(a).to(dtype=torch.long) for a in graph_tup.edge_positions]\n",
    "print('graph_tup.edge_positions', [x.shape for x in graph_tup.edge_positions])\n",
    "edge_pos = np.hstack(graph_tup.edge_positions)\n",
    "\n",
    "edge_attr = np.vstack([edge_attr, edge_pos])\n",
    "\n",
    "edge_attr = torch.from_numpy(edge_attr.T).to(torch.long)\n",
    "print('edge_attr', edge_attr.size())\n",
    "\n",
    "# node_x as data.x\n",
    "x = torch.from_numpy(graph_tup.node_x).to(torch.long) #\n",
    "y = torch.from_numpy(np.array(42)).to(torch.long).view(1)\n",
    "print('x', x.size())\n",
    "print('y', y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple2data(graph_tup, class_label):\n",
    "    # edges as data.edge_index\n",
    "    # list of <M_i, 2> tensors  (M_i = num_edges for ith edge type)\n",
    "    edge_indices = [torch.from_numpy(a).to(dtype=torch.long) for a in graph_tup.adjacencies] # list of <M_i, 2>\n",
    "\n",
    "    edge_index = torch.cat(edge_indices, dim=0).t().contiguous() # <2, M>\n",
    "\n",
    "    # (edge_type, edge_position) as data.edge_attr of shape <M, 2>\n",
    "    edge_types = [i * np.ones_like(edge_indices[i])[:,0] for i in range(len(edge_indices))]\n",
    "    edge_types = np.hstack(edge_types)\n",
    "    edge_pos = np.hstack(graph_tup.edge_positions)\n",
    "    edge_attr = np.vstack([edge_types, edge_pos]).T\n",
    "    \n",
    "    edge_attr = torch.from_numpy(edge_attr).to(dtype=torch.long).contiguous()  # <M, 2>\n",
    "    \n",
    "    assert edge_attr.size()[0] == edge_index.size()[1], f'edge_attr={edge_attr.size()} size mismatch with edge_index={edge_index.size()}'\n",
    "    \n",
    "    # node_x as data.x\n",
    "    x = torch.from_numpy(graph_tup.node_x).to(torch.long)  # <N, 1>\n",
    "    # class label as y\n",
    "    y = torch.from_numpy(np.array(class_label)).to(torch.long).view(1)  # <1>\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[418, 2], edge_index=[2, 418], x=[250, 1], y=[1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tuple2data example\n",
    "tuple2data(graph_tup, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "def dump(outfile, data, mkdir=True):\n",
    "    if mkdir:\n",
    "        outfile.parent.mkdir(exist_ok=True, parents=True)\n",
    "    with open(outfile, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ds_raw_dir(ds_base, dump_nx=True, dump_tuple=True, dump_data=True):\n",
    "    \"\"\"Preprocess all .ll files in folders named by class ids e.g. ds_base/1, ds_base/2, ...\n",
    "    into pytorch-geometric data.Data instances.\n",
    "    \n",
    "    The intermediate nx graphs and graph_tuples can be saved as well.\n",
    "    \"\"\"\n",
    "\n",
    "    out_base = ds_base.parent / (ds_base.name + '_programl')\n",
    "    out_base.mkdir(parents=True, exist_ok=True)\n",
    "    problems = open(out_base / 'problems.txt', 'a')\n",
    "    print(f\"=== DATASET {ds_base}: preprocessing will be saved in {out_base}\")\n",
    "\n",
    "    # get all subfolders 1/ 2/ etc\n",
    "    folders = [x for x in ds_base.glob('*') if x.is_dir()]\n",
    "\n",
    "    for i, folder in enumerate(folders):\n",
    "        try:\n",
    "            int(folder.name)\n",
    "        except ValueError as e:\n",
    "            print(f\"Folder {i} has to be named with integervalues, but is {folder.name}.\")\n",
    "            raise e\n",
    "    \n",
    "    # multiprocessed loop over folders\n",
    "    pool = Pool(processes=12)\n",
    "    task_args = [(folder, dump_nx, dump_tuple, dump_data, out_base) for folder in folders]\n",
    "    \n",
    "    for probs in tqdm.tqdm(pool.imap(_process_single_folder, task_args), total=len(task_args)):\n",
    "        print(probs, file=problems)\n",
    "    \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    problems.close()\n",
    "    print(f\" * COMPLETED * === DATASET {ds_base}: preprocessing saved to {out_base}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _process_single_folder(args):\n",
    "    folder, dump_nx, dump_tuple, dump_data, out_base = args\n",
    "    problems = \"\"\n",
    "    \n",
    "    print(f\"=== Opening Folder {str(folder)} ===\")\n",
    "    \n",
    "    label = int(folder.name)\n",
    "    files = list(folder.glob('*.ll'))\n",
    "    for i, file in enumerate(files):\n",
    "        \n",
    "        # ~~~ step 1: .ll --> nx ~~~\n",
    "        \n",
    "        outfile = out_base / '_nx' / folder.name / (file.name.rsplit('.', 1)[0] + '.nx.p')\n",
    "        if outfile.is_file():\n",
    "            nx_graph = load(outfile)\n",
    "        else:\n",
    "            if i % 100 == 0:\n",
    "                print(f\"{folder.name} - [{i}/{len(files)}] Processing {str(file)} ...\")\n",
    "            with open(file, 'r') as f:\n",
    "                bytecode = f.read()\n",
    "            try:\n",
    "                nx_graph = builder.Build(bytecode) # nx\n",
    "                if dump_nx:\n",
    "                    dump(outfile, nx_graph)\n",
    "            except:\n",
    "                print(f\"***** FAILING ON {str(file)} .................. \")\n",
    "                problems += str(file)\n",
    "                problems += '\\n'\n",
    "                continue\n",
    "\n",
    "\n",
    "        # ~~~ step 2: nx --> tuple ~~~\n",
    "        \n",
    "        outfile = out_base / '_tuples' / folder.name / (file.name.rsplit('.', 1)[0] + '.tuple.p')\n",
    "        if outfile.is_file():\n",
    "            graph_tup = load(outfile)\n",
    "        else:\n",
    "            graph_tup = graph_tuple.GraphTuple.CreateFromNetworkX(nx_graph)\n",
    "            if dump_tuple:\n",
    "                dump(outfile, graph_tup)\n",
    "\n",
    "        # step 3: tuple --> data\n",
    "        outfile = out_base / folder.name / (file.name.rsplit('.', 1)[0] + '.data.p')\n",
    "        if outfile.is_file():\n",
    "            continue\n",
    "        data = tuple2data(graph_tup, class_label=label)\n",
    "        dump(outfile, data)\n",
    "\n",
    "    return problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds_base = Path('classifyapp_data/ir_val')\n",
    "print(ds_base.name)\n",
    "\n",
    "preprocess_ds_raw_dir(ds_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class POJ104(InMemoryDataset):\n",
    "#    torch_geometric.data.InMemoryDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds_base = Path('classifyapp_data/ir_test')\n",
    "print(ds_base.name)\n",
    "\n",
    "preprocess_ds_raw_dir(ds_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocess_ds_raw_dir(Path('classifyapp_data/ir_train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
