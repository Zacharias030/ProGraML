{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Dense-vs-Sparse-Self-Attention\" data-toc-modified-id=\"Dense-vs-Sparse-Self-Attention-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Dense vs Sparse Self-Attention</a></span><ul class=\"toc-item\"><li><span><a href=\"#Check-equality-of-sparse-implementation-with-reference\" data-toc-modified-id=\"Check-equality-of-sparse-implementation-with-reference-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Check equality of sparse implementation with reference</a></span></li></ul></li><li><span><a href=\"#Benchmarking-Sparse-vs-Dense-Self-Attention\" data-toc-modified-id=\"Benchmarking-Sparse-vs-Dense-Self-Attention-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Benchmarking Sparse vs Dense Self-Attention</a></span></li><li><span><a href=\"#scatter_add-vs-index_add\" data-toc-modified-id=\"scatter_add-vs-index_add-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>scatter_add vs index_add</a></span></li><li><span><a href=\"#embedding-lookup-vs-index_select\" data-toc-modified-id=\"embedding-lookup-vs-index_select-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>embedding lookup vs index_select</a></span><ul class=\"toc-item\"><li><span><a href=\"#Scattered-GRU-input\" data-toc-modified-id=\"Scattered-GRU-input-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Scattered GRU input</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zacharias/ProGraML/deeplearning/ml4pl/poj104\n",
      "/home/zacharias/ProGraML\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, os\n",
    "\n",
    "# make this file executable from anywhere\n",
    "#if __name__ == '__main__':\n",
    "\n",
    "# in editor\n",
    "#full_path = os.path.realpath(__file__)\n",
    "\n",
    "# in jupyter\n",
    "full_path = !pwd\n",
    "full_path = full_path[0]\n",
    "\n",
    "\n",
    "print(full_path)\n",
    "REPO_ROOT = full_path.rsplit('ProGraML', maxsplit=1)[0] + 'ProGraML'\n",
    "print(REPO_ROOT)\n",
    "#insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, REPO_ROOT)\n",
    "REPO_ROOT = Path(REPO_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric import utils\n",
    "from torch_geometric.utils import softmax as scatter_softmax\n",
    "from torch_geometric.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplearning.ml4pl.models.ggnn.modeling import SelfAttentionMessageLayer\n",
    "from deeplearning.ml4pl.models.ggnn.configs import ProGraMLBaseConfig, GraphTransformerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplearning.ml4pl.models.ggnn.modeling import (\n",
    "    SelfAttentionMessageLayer, TransformerUpdateLayer, NodeEmbeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing with random embeddings\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing with random embeddings\n"
     ]
    }
   ],
   "source": [
    "config = GraphTransformerConfig()\n",
    "ne = NodeEmbeddings(config)\n",
    "x = torch.randint(8568,(10000,))\n",
    "ns = ne(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5007,  0.7786,  0.5091,  ..., -0.0390,  0.6470, -1.4075],\n",
       "        [ 1.2099, -1.3119, -0.6140,  ..., -0.2688, -1.7967,  0.7093],\n",
       "        [ 0.6308,  1.4290, -0.9300,  ...,  1.3073,  1.8656,  0.1631],\n",
       "        ...,\n",
       "        [-0.8768, -0.7936, -1.6952,  ..., -1.6305, -0.2348,  2.2083],\n",
       "        [ 0.0888, -1.3549,  0.4236,  ...,  1.0144, -1.3774, -1.1813],\n",
       "        [-0.1278, -0.7307, -1.4278,  ...,  1.2174, -1.8258, -0.5256]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0013, grad_fn=<StdMeanBackward1>),\n",
       " tensor(-0.0001, grad_fn=<StdMeanBackward1>))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std_mean(ns.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ns.view(-1).detach().numpy(), bins=100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu = TransformerUpdateLayer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0000, grad_fn=<StdMeanBackward1>),\n",
       " tensor(-3.4937e-10, grad_fn=<StdMeanBackward1>))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = tu(ns, ns)\n",
    "torch.std_mean(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# att = SelfAttentionMessageLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real data\n",
    "from deeplearning.ml4pl.poj104.dataset import POJ104Dataset\n",
    "ds_dir = REPO_ROOT / 'deeplearning/ml4pl/poj104/classifyapp_data'\n",
    "valid_data = POJ104Dataset(ds_dir, 'val')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 2 required positional arguments: 'messages' and 'node_states'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2e36e8f84c83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 2 required positional arguments: 'messages' and 'node_states'"
     ]
    }
   ],
   "source": [
    "tu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense vs Sparse Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_state_dict(mod):\n",
    "    for n, t in mod.state_dict().items():\n",
    "        print(n, t.size())\n",
    "\n",
    "def num_parameters(mod) -> int:\n",
    "    \"\"\"Compute the number of trainable parameters in a nn.Module and its children.\"\"\"\n",
    "    num_params = sum(param.numel() for param in mod.parameters(recurse=True) if param.requires_grad)\n",
    "    return num_params, f\"{num_params * 4 / 1e6:.3f}MB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BaseConfig.from_dict({\n",
    "    'edge_type_count': 3,\n",
    "    'backward_edges': True,\n",
    "    'hidden_size': 200,\n",
    "    'transformer_attn_bias': True,\n",
    "    'transformer_num_heads': 8,\n",
    "    'transformer_attn_dropout': 0.0,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check equality of sparse implementation with reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_attn = SelfAttentionMessageLayer(config).to(device='cuda')\n",
    "\n",
    "#print_state_dict(sparse_attn)\n",
    "#print(\"\")\n",
    "#print(sparse_attn)\n",
    "#print(\"\")\n",
    "#num_parameters(sparse_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummy data\n",
    "\n",
    "num_n = 5\n",
    "heads = 8\n",
    "hidd = 200\n",
    "\n",
    "random_emb = nn.Parameter(torch.randn(9000, hidd, device='cuda'), requires_grad=True)\n",
    "\n",
    "ones = torch.ones(num_n, num_n, device='cuda')\n",
    "\n",
    "adj = torch.tril(ones, diagonal=0)\n",
    "#adj = ones\n",
    "print(\"adj matrix: edges go from (row -> column) if [row, column] == 1\")\n",
    "print(adj)\n",
    "\n",
    "attn_mask = torch.tril(ones * float('-inf'), diagonal=-1)\n",
    "\n",
    "print(\"\")\n",
    "print(\"attn_mask.t(): We print the transposed attention mask,\")\n",
    "print(\"bc. the reference implementation indexes the attn_mask <target, src>\")\n",
    "print(attn_mask.t())\n",
    "\n",
    "edge_index = utils.dense_to_sparse(adj)[0]\n",
    "print(edge_index.size())\n",
    "#print(edge_index.t()[:10])\n",
    "\n",
    "x = torch.randint(9000, (num_n,))\n",
    "print(x.size())\n",
    "\n",
    "node_states = random_emb[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sparse attn on dummy data\n",
    "sa_node_states, sa_weights = sparse_attn(edges=edge_index, node_states=node_states)\n",
    "sa_sum = torch.sum(sa_node_states)\n",
    "\n",
    "print(sa_sum)\n",
    "\n",
    "\n",
    "in_proj = sparse_attn.qkv_in_proj.weight\n",
    "in_proj_bias = sparse_attn.qkv_in_proj.bias\n",
    "out_proj = sparse_attn.out_proj.weight\n",
    "out_proj_bias = sparse_attn.out_proj.bias\n",
    "\n",
    "\n",
    "ns = node_states.unsqueeze(1)\n",
    "da_node_states, da_weights = F.multi_head_attention_forward(\n",
    "                ns, ns, ns, 200, 8,\n",
    "                in_proj, in_proj_bias,\n",
    "                None, None, False,\n",
    "                0.0, out_proj, out_proj_bias,\n",
    "                training=False,\n",
    "                key_padding_mask=None, need_weights=True, \n",
    "                attn_mask=attn_mask)\n",
    "da_sum = torch.sum(da_node_states)\n",
    "\n",
    "\n",
    "# reformat\n",
    "da_node_states = da_node_states.squeeze()\n",
    "da_weights = da_weights.squeeze().t()\n",
    "\n",
    "print(da_sum)\n",
    "\n",
    "print(da_weights)\n",
    "\n",
    "\n",
    "sa_weights_matrix = torch.zeros(num_n, num_n, device='cuda')\n",
    "for i, (s, t) in enumerate(edge_index.t()):\n",
    "    sa_weights_matrix[s, t] = sa_weights[i]\n",
    "print(sa_weights_matrix)\n",
    "#print(sa_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert similarity of sums of outputs\n",
    "check1 = torch.abs(sa_sum - da_sum)\n",
    "print((check1 < 1e-7).item())\n",
    "print(torch.max(check1).item())\n",
    "# assert similarity of attention weights for complete graphs\n",
    "check2 = torch.abs(da_weights - sa_weights_matrix )\n",
    "print(torch.all(check2 < 1e-7).item())\n",
    "print(torch.max(check2).item())\n",
    "\n",
    "# assert similarity of self-attention output (new node states)\n",
    "check3 = torch.abs(da_node_states - sa_node_states)\n",
    "print(torch.all(check3 < 1e-7).item())\n",
    "print(torch.max(check3).item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Sparse vs Dense Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def satt(x, emb_table, edge_index):\n",
    "    node_states = emb_table[x]\n",
    "    s = sparse_attn(edges=edge_index, node_states=node_states)\n",
    "    loss = torch.sum(s[0])\n",
    "    loss.backward()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "def datt(x, emb_table, attn_mask):\n",
    "    query = emb_table[x.unsqueeze(1)]\n",
    "    s = dense_attn(query, query, query, attn_mask=attn_mask, need_weights=False)\n",
    "    loss = torch.sum(s[0])\n",
    "    loss.backward()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "def benchmark_on_causal(s,n):\n",
    "    for num_n in [2**i for i in range(s,n+1)]:\n",
    "        print(num_n)\n",
    "        with torch.no_grad():\n",
    "            causal_mask = (torch.triu(torch.ones(num_n, num_n, device='cuda')) - 1) * 1e4\n",
    "            edge_index = utils.dense_to_sparse(causal_mask)[0]\n",
    "            print(edge_index.size())\n",
    "            x = torch.randint(9000, (num_n,))\n",
    "        torch.cuda.synchronize()\n",
    "        #print(\"sparse\")\n",
    "        %timeit satt(x, random_emb, edge_index)\n",
    "        \n",
    "        #print(\"dense\")\n",
    "        try:\n",
    "            %timeit datt(x, random_emb, causal_mask)\n",
    "        except RuntimeError:\n",
    "            print(\"Dense OOM\")\n",
    "        del causal_mask\n",
    "        del edge_index\n",
    "        del x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_on_causal(8, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def benchmark_on_real(s,n):\n",
    "    for bsz in [2**i for i in range(s,n+1)]:\n",
    "        dl = DataLoader(valid_data, batch_size=bsz)\n",
    "        print(bsz)\n",
    "        for graph in dl:\n",
    "            graph.to(device='cuda')\n",
    "            print(graph)\n",
    "            break\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = graph.x[:,0]\n",
    "            edge_index = graph.edge_index\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        %timeit satt(x, random_emb, edge_index)\n",
    "        \n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                mask = (1 - utils.to_dense_adj(graph.edge_index).squeeze() ) * -10000\n",
    "                print(f\"Size of adjacency matrix: {mask.size()[0]**2 * 4 / 1e6:,.2f} MB\")\n",
    "            torch.cuda.synchronize()    \n",
    "            %timeit datt(x, random_emb, mask)\n",
    "        except RuntimeError:\n",
    "            print(\"Dense OOM\")\n",
    "            \n",
    "        print(\"----\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "benchmark_on_real(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(valid_data, batch_size=64)\n",
    "for graph in dl:\n",
    "    graph.to(device='cuda')\n",
    "    break\n",
    "print(graph)\n",
    "\n",
    "with torch.no_grad():\n",
    "    adj = (1 - to_dense_adj(graph.edge_index).squeeze() ) * -10000\n",
    "adj.size(), adj.device\n",
    "print(f\"Size of adjacency matrix: {adj.size()[0]**2 * 4 / 1e6:,.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scatter_add vs index_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-06e359bb4625>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.randn(2000,200, requires_grad=True, device='cuda')\n",
    "mbs = torch.randn(10000, 200, device='cuda', requires_grad=True)\n",
    "index = torch.randint(0, 2000, [10000], device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = torch.zeros_like(target)\n",
    "sa.scatter_add_(0, index.unsqueeze(1).repeat(1, 200), mbs)\n",
    "\n",
    "s = torch.zeros_like(target)\n",
    "s.index_add_(0, index, mbs)\n",
    "\n",
    "torch.max(torch.abs(sa - s)), torch.argmax(torch.abs(sa - s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ia():\n",
    "    s = torch.zeros_like(target)\n",
    "    s.index_add_(0, index, mbs)\n",
    "    loss = torch.sum(s)\n",
    "    loss.backward()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "def sa():\n",
    "    s = torch.zeros_like(target)\n",
    "    s.scatter_add_(0, index.unsqueeze(1).repeat(1, 200), mbs)\n",
    "    loss = torch.sum(s)\n",
    "    loss.backward()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    \n",
    "torch.cuda.synchronize()    \n",
    "%timeit ia()\n",
    "%timeit sa()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# embedding lookup vs index_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "bs = 2000\n",
    "mask = torch.randn(bs, device='cuda')\n",
    "mask2 = mask>0\n",
    "index = torch.randint(0, 2000, [10000], dtype=torch.long, device='cuda')\n",
    "\n",
    "target = torch.randn(bs,200, requires_grad=True, device='cuda')\n",
    "pred = torch.randn(bs,200, requires_grad=True, device='cuda')\n",
    "\n",
    "h = torch.nn.GRUCell(200, 200).to(device='cuda')\n",
    "g = torch.nn.GRUCell(200, 200).to(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.equal(F.embedding(index, target), torch.index_select(target, dim=0, index=index))\n",
    "torch.index_select(target, dim=0, index=index).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def emb():\n",
    "    selected = F.embedding(index, target)\n",
    "    loss = torch.sum(selected)\n",
    "    loss.backward()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "def index_select():\n",
    "    selected = torch.index_select(target, dim=0, index=index)\n",
    "    loss = torch.sum(selected)\n",
    "    loss.backward()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "%timeit emb()\n",
    "%timeit index_select()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Scattered GRU input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def fn1():\n",
    "    a = torch.zeros_like(target,device='cuda')\n",
    "    a[mask2] += g(target[mask2])\n",
    "    a[~mask2] += h(target[~mask2])\n",
    "    \n",
    "    loss = torch.sum(a)\n",
    "    loss.backward()\n",
    "    torch.cuda.synchronize()\n",
    "    return loss\n",
    "\n",
    "l = fn1()\n",
    "\n",
    "def fn2():\n",
    "    a = torch.zeros_like(target,device='cuda')\n",
    "    a += mask2.view(-1, 1) * g(target)\n",
    "    a += ~mask2.view(-1, 1) * h(target)\n",
    "    loss = torch.sum(a)\n",
    "    loss.backward()\n",
    "    torch.cuda.synchronize()\n",
    "    return loss\n",
    "\n",
    "ll = fn2()\n",
    "    \n",
    "torch.cuda.synchronize()\n",
    "\n",
    "%timeit fn1()\n",
    "%timeit fn2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(ll)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def fn1():\n",
    "    loss = torch.sum(mask.view(-1, 1) * (target - pred) ** 2)\n",
    "    loss.backward()\n",
    "    torch.cuda.synchronize()\n",
    "def fn2():\n",
    "    loss = torch.sum((target[mask2,:] - pred[mask2,:]) ** 2)\n",
    "    loss.backward()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "%timeit fn1()\n",
    "%timeit fn2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
